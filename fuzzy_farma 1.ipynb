{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e0251-c8eb-459e-9a89-09e1a1a00d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "import datetime\n",
    "import os\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390db5db-0bc6-4a35-b575-3895dfeb839f",
   "metadata": {},
   "source": [
    "# VARIABLES TO ADJUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79813b9-4fa3-4388-8214-887ef7d571b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "now= datetime.datetime.now()\n",
    "dt_format = '%Y-%m-%d'\n",
    "strToday = now.strftime(dt_format)\n",
    "strToday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d9fde-3526-4bd9-8a37-83378b39966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_name = 'soriana' # will be placed in the final file name\n",
    "client_file_name ='soriana.csv' \n",
    "filter_file_name = 'mp_competencia.xlsx'\n",
    "\n",
    "#Save and Read paths\n",
    "path = f'C:/Users/IvanMinauro/Documents/fuzzy/fuzzy'\n",
    "path_base = f'C:/Users/IvanMinauro/Documents/fuzzy/fuzzy/client_data/'\n",
    "path_comparar = f'C:/Users/IvanMinauro/Documents/fuzzy/fuzzy/competitors_csv/'\n",
    "final_file_name = f'C:/Users/IvanMinauro/Documents/fuzzy/fuzzy/match_comparisson_{customer_name}_{strToday}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63981ada-e00d-4429-a5ff-97244033c569",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc13fec-4056-4421-ab87-d19c6d810d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "\n",
    "#Comment test git\n",
    "LIST_COLUMN_ORDER = ['Date', 'Canal', 'Category', 'Subcategory', 'Subcategory2', 'Subcategory3', 'Marca',\n",
    "                     'Modelo', 'SKU', 'UPC', 'Item', 'Item Characteristics', 'URL SKU', 'Image', 'Price',\n",
    "                     'Sale Price', 'Shipment Cost', 'Sales Flag', 'Store ID', 'Store Name',\n",
    "                     'Store Address', 'Stock', 'UPC WM2', 'Final Price', 'UPC WM', 'COMP']\n",
    "\n",
    "LIST_COLUMN_ORDER_SHORT = ['Date', 'Canal', 'Category', 'Subcategory', 'Subcategory2', 'Subcategory3', 'Marca',\n",
    "                     'Modelo', 'SKU', 'UPC', 'Item', 'Item Characteristics', 'URL SKU', 'Image', 'Price',\n",
    "                     'Sale Price', 'Shipment Cost', 'Sales Flag', 'Store ID', 'Store Name',\n",
    "                     'Store Address', 'Stock', 'UPC WM', 'Final Price']\n",
    "\n",
    "LIST_COLUMN_ORDER_M = ['Date', 'Canal', 'Category', 'Subcategory', 'Subcategory2', 'Subcategory3', 'Marca',\n",
    "                      'Modelo', 'SKU', 'UPC', 'Item', 'Item Characteristics', 'URL SKU', 'Image', 'Price',\n",
    "                      'Sale Price', 'Shipment Cost', 'Sales Flag', 'Store ID', 'Store Name',\n",
    "                      'Store Address', 'Stock', 'UPC WM2', 'Final Price', 'UPC WM', 'COMP',\n",
    "                      'GR', 'CAT C', 'SUB C', 'MARCA C'\t, 'Precio Gramo', 'MARCA 2', 'Congelado']\n",
    "\n",
    "COMPETITORS_FLOAT_COLUMNS = ['Price', 'Final Price', 'Sale Price']\n",
    "COMPETITORS_STRING_COLUMNS = ['UPC', 'EAN', 'UPC WM', 'UPC WM2']\n",
    "COMPARISON_STRING_COLUMNS = ['upc_wm2_client', 'match', 'upc_wm2_competitor']\n",
    "\n",
    "#Start Data Frame Utils\n",
    "\n",
    "#This section is only for functions that work on columns of a Data Frame\n",
    "#   object. To call them use the class method apply().\n",
    "def create_upc_wm(strUPC, strChannel = ''):\n",
    "    \n",
    "    if strUPC.isdigit():\n",
    "        if 'Walmart' in strChannel or 'walmart' in strChannel:\n",
    "            pass\n",
    "        else:\n",
    "            if len(strUPC) > 7:\n",
    "                strUPC = strUPC[:-1]\n",
    "    \n",
    "        while len(strUPC) < 16:\n",
    "                strUPC = '0' + strUPC\n",
    "                \n",
    "    return strUPC\n",
    "\n",
    "def select_upc_wm2(strUPCWM_Competitors, strUPCWM_Comparison):\n",
    "    if pd.isna(strUPCWM_Comparison):\n",
    "        return strUPCWM_Competitors\n",
    "    else:\n",
    "        return strUPCWM_Comparison\n",
    "\n",
    "def get_weights(strItem, regPattern):\n",
    "    #Buscar optimizar esta sección\n",
    "\n",
    "    lstGram_Names = ['g', 'gr', 'gramo', 'gramos', 'grms', 'grm']\n",
    "    lstFuzzy_Words = ['granos']\n",
    "\n",
    "    for strFuzzy_Word in lstFuzzy_Words:\n",
    "        strItem = strItem.replace(strFuzzy_Word, \"\")\n",
    "\n",
    "    if any(strGram_Name in strItem for strGram_Name in lstGram_Names):\n",
    "        strExtraction = strItem.replace(' ',  '')\n",
    "\n",
    "        if regPattern.search(strExtraction):\n",
    "            strExtraction = regPattern.search(strExtraction)\n",
    "            strExtraction = strExtraction.group(1)\n",
    "\n",
    "            strExtraction = strExtraction.replace('g', '')\n",
    "            return strExtraction\n",
    "        else:\n",
    "            return '0'\n",
    "    elif 'bolzalza' in strItem:\n",
    "        return 'Bolzalza'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "def get_weights_kilograms(strItem, regPattern):\n",
    "    #Buscar optimizar esta sección\n",
    "\n",
    "    lstGram_Names = ['kg', 'kgr', 'kilogramo', 'kilo']\n",
    "\n",
    "    if any(strGram_Name in strItem for strGram_Name in lstGram_Names):\n",
    "        strExtraction = strItem.replace(' ',  '')\n",
    "\n",
    "        if regPattern.search(strExtraction):\n",
    "            strExtraction = regPattern.search(strExtraction)\n",
    "            strExtraction = strExtraction.group(1)\n",
    "\n",
    "            strExtraction = strExtraction.replace('k', '')\n",
    "            fltExtraction = float(strExtraction) * 1000\n",
    "\n",
    "            return str(fltExtraction)\n",
    "        else:\n",
    "            return '0'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "def calculate_discount(fltPrice, fltFinal_Price):\n",
    "    return 1 - (fltFinal_Price / fltPrice)\n",
    "\n",
    "def calculate_price_per_kg(fltFinal_Price, strGram, boolIts_Pack = False):\n",
    "    if strGram != 'Bolzalza' and strGram != '0' and boolIts_Pack == False:\n",
    "        fltGram = float(strGram)\n",
    "        fltPrice_Gram = fltFinal_Price / fltGram\n",
    "        fltPrice_Gram = fltPrice_Gram * 1000\n",
    "\n",
    "        return fltPrice_Gram\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def determine_if_pack(strItem):\n",
    "    lstPieces_Names = ['piezas', 'pzs', 'pzas']\n",
    "\n",
    "    if any(strPieces_Name in strItem for strPieces_Name in lstPieces_Names):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#End Data Frame Utils\n",
    "\n",
    "#Start File Util Functions\n",
    "def convert_excel_to_df(strExcel_Path):\n",
    "    lstSheets = pd.ExcelFile(strExcel_Path).sheet_names\n",
    "\n",
    "    dfConcat_Excel = pd.concat([pd.read_excel(strExcel_Path, sheet_name = strSheet_Name) for strSheet_Name\n",
    "                           in lstSheets], ignore_index = True)\n",
    "\n",
    "    return dfConcat_Excel\n",
    "\n",
    "def consolidate_competitors_df(strPath_Read, lstItem_Words = []):\n",
    "    if len(strPath_Read) < 3:\n",
    "        raise ValueError('Path is too short for a valid file location.')\n",
    "\n",
    "    lstFilenames = glob.glob(strPath_Read + \"\\*.csv\") #Toma de ese path los archivos que tengan como extención csv\n",
    "\n",
    "    lstDFs_Concat = []\n",
    "    for strFilename in lstFilenames: #Nombre del los csv\n",
    "        print(strFilename)\n",
    "        dfAux = pd.read_csv(strFilename, dtype = str) #dataframe leido por iteracion\n",
    "\n",
    "        lstColumns = dfAux.columns.to_list() #Nombres de las columnas\n",
    "        dictNew_Columns = homogonize_column_names(lstColumns)\n",
    "        dfAux.rename(columns = dictNew_Columns, inplace = True)\n",
    "\n",
    "        lstDFs_Concat.append(dfAux) #añadir a lista de dataframes\n",
    "\n",
    "    dfConsolidated_Competitors = pd.concat(lstDFs_Concat) #Concatenar lista de dataframe a un solo dataframe\n",
    "\n",
    "    if len(lstItem_Words) > 0:\n",
    "        dfConsolidated_Competitors = dfConsolidated_Competitors[\n",
    "                                        dfConsolidated_Competitors['Item'].str.contains('|'.join(lstItem_Words))\n",
    "                                        ].reset_index(drop = True) #Filtrar por palabras\n",
    "\n",
    "    dfConsolidated_Competitors.drop(columns=['UPC WM'], inplace = True) #Eliminar UPC WN\n",
    "    dfConsolidated_Competitors['UPC'] = dfConsolidated_Competitors['UPC'].str.replace('\\.0+$', '',\n",
    "                                           regex = True)\n",
    "    dfConsolidated_Competitors['UPC'] = dfConsolidated_Competitors['UPC'].fillna('')\n",
    "    dfConsolidated_Competitors['UPC'] = dfConsolidated_Competitors['UPC'].astype(str)\n",
    "    dfConsolidated_Competitors['Canal'] = dfConsolidated_Competitors['Canal'].astype(str)\n",
    "    dfConsolidated_Competitors['UPC WM'] = dfConsolidated_Competitors.apply(lambda row:\n",
    "                                             create_upc_wm(row['UPC'], row['Canal']), axis = 1)\n",
    "    dfConsolidated_Competitors['UPC WM2'] = dfConsolidated_Competitors['UPC WM']\n",
    "\n",
    "\n",
    "    dfConsolidated_Competitors[COMPETITORS_FLOAT_COLUMNS] = dfConsolidated_Competitors[COMPETITORS_FLOAT_COLUMNS].replace(\n",
    "                                                                {'\\$': '',\n",
    "                                                                 ',': '',\n",
    "                                                                 r'\\[': '',\n",
    "                                                                 r'\\]': '',\n",
    "                                                                 'Price': '0'}, regex = True) #Reemplazar ciertos caracteres\n",
    "\n",
    "    #dfConsolidated_Competitors[COMPETITORS_FLOAT_COLUMNS] = dfConsolidated_Competitors[COMPETITORS_FLOAT_COLUMNS].astype(float)\n",
    "\n",
    "    dfConsolidated_Competitors['COMP'] = ''\n",
    "\n",
    "    dfConsolidated_Competitors = dfConsolidated_Competitors[LIST_COLUMN_ORDER] #Ordenar dataframe\n",
    "\n",
    "    dfConsolidated_Competitors = dfConsolidated_Competitors[(dfConsolidated_Competitors['Price'].notna()) |\n",
    "                                                            (dfConsolidated_Competitors['Price'] != '0')] #Filtrar por precio vacio\n",
    "\n",
    "    return dfConsolidated_Competitors\n",
    "\n",
    "def get_comparison_df(strPath_Comparison_File, strSheet_Name):\n",
    "    dictComparison_Dtypes = {strColumn_Name: 'str' for strColumn_Name in COMPARISON_STRING_COLUMNS}\n",
    "\n",
    "    dfComparison = pd.read_excel(strPath_Comparison_File, sheet_name = strSheet_Name,\n",
    "                                dtype = dictComparison_Dtypes)\n",
    "\n",
    "    dfComparison = dfComparison[['upc_wm2_client', 'match', 'upc_wm2_competitor']]\n",
    "    dfComparison = dfComparison.dropna(subset = ['upc_wm2_competitor'])\n",
    "    dfComparison.drop_duplicates(inplace = True)\n",
    "\n",
    "    return dfComparison\n",
    "\n",
    "def replace_upc_wm2(dfCompetitors, dfComparison):\n",
    "    dfCompetitors = dfCompetitors.merge(dfComparison, how = 'left' ,left_on = 'UPC WM2', right_on = 'upc_wm2_competitor')\n",
    "\n",
    "    dfCompetitors['UPC WM'] = dfCompetitors.apply(lambda row:  select_upc_wm2(row['UPC WM2'],\n",
    "                                  row['upc_wm2_client']), axis = 1)\n",
    "\n",
    "    dfCompetitors.drop(columns = COMPARISON_STRING_COLUMNS, inplace = True)\n",
    "\n",
    "    return dfCompetitors\n",
    "\n",
    "def extract_weight(dfCompetitors):\n",
    "    strRegex_Grams = '([0-9]+\\.?[0-9]*\\s?g)'\n",
    "    strRegex_Kgs = '([0-9]+\\.?[0-9]*\\s?k)'\n",
    "    lstPer_KG_Names = ['por kilo', 'el kilo', 'por kg', 'kg', 'kilo']\n",
    "\n",
    "    regPattern_Grams = re.compile(strRegex_Grams)\n",
    "    regPattern_KG = re.compile(strRegex_Kgs)\n",
    "\n",
    "    dfCompetitors['aux_item'] = dfCompetitors['Item']\n",
    "    dfCompetitors['aux_item'] = dfCompetitors['aux_item'].astype(str)\n",
    "    dfCompetitors['aux_item'] = dfCompetitors['aux_item'].str.lower()\n",
    "    dfCompetitors['aux_item'] = dfCompetitors['aux_item'].str.replace('-', '')\n",
    "\n",
    "    dfCompetitors_Kilos = dfCompetitors[dfCompetitors['aux_item'].str.contains(strRegex_Kgs,\n",
    "                             regex = True)].reset_index(drop = True)\n",
    "    dfCompetitors_aux = dfCompetitors[~dfCompetitors['aux_item'].str.contains(strRegex_Kgs,\n",
    "                            regex = True)].reset_index(drop = True)\n",
    "\n",
    "    dfCompetitors_Kilos['Cantidad'] = dfCompetitors_Kilos.apply(lambda row: get_weights_kilograms(row['aux_item'],\n",
    "                                   regPattern_KG), axis = 1, result_type = 'reduce')\n",
    "\n",
    "    dfCompetitors_Grams = dfCompetitors_aux[dfCompetitors_aux['aux_item'].str.contains(strRegex_Grams,\n",
    "                              regex = True)].reset_index(drop = True)\n",
    "    dfCompetitors_aux = dfCompetitors_aux[~dfCompetitors_aux['aux_item'].str.contains(strRegex_Grams\n",
    "                            )].reset_index(drop = True)\n",
    "\n",
    "    dfCompetitors_Grams['Cantidad'] = dfCompetitors_Grams.apply(lambda row: get_weights(row['aux_item'],\n",
    "                               regPattern_Grams), axis = 1, result_type = 'reduce')\n",
    "\n",
    "    dfCompetitor_One_Kilo = dfCompetitors_aux[(dfCompetitors_aux['aux_item'].str.contains('|'.join(lstPer_KG_Names),\n",
    "                                regex = True))].reset_index(drop = True)\n",
    "    dfCompetitors_aux = dfCompetitors_aux[(~dfCompetitors_aux['aux_item'].str.contains('|'.join(lstPer_KG_Names),\n",
    "                            regex = True))].reset_index(drop = True)\n",
    "\n",
    "    dfCompetitor_One_Kilo['Cantidad'] = 1000\n",
    "\n",
    "    dfCompetitors_aux['Cantidad'] = 0\n",
    "\n",
    "    dfCompetitors = pd.concat([dfCompetitors_Kilos, dfCompetitors_Grams, dfCompetitor_One_Kilo, dfCompetitors_aux],\n",
    "                        ignore_index = True)\n",
    "\n",
    "    dfCompetitors['Unidad'] = 'gr'\n",
    "\n",
    "    dfCompetitors.drop(columns = ['aux_item'], inplace = True)\n",
    "\n",
    "    return dfCompetitors\n",
    "\n",
    "def extract_ml(dfCompetitors):\n",
    "    reMililiters = re.compile(r'[0-9]+\\.?[0-9]*ml', re.IGNORECASE)\n",
    "\n",
    "    lstIndexs = [j for j in range(len(dfCompetitors))]\n",
    "    dfCompetitors['Cantidad'] = list(map(lambda i: \"\".join(reMililiters.findall(dfCompetitors.Item[i].replace(\" ml\", \"ml\").replace(\" - \", \"\")))[:-2] , lstIndexs))\n",
    "\n",
    "    dfCompetitors.loc[dfCompetitors.Cantidad == \"\", 'Cantidad'] = 0\n",
    "    dfCompetitors.Cantidad = dfCompetitors.Cantidad.astype(float)\n",
    "    dfCompetitors['Unidad'] = 'ml'\n",
    "\n",
    "    return dfCompetitors\n",
    "\n",
    "def extract_quantities_and_units(dfCompetitors):\n",
    "    dfCompetitors = extract_ml(dfCompetitors)\n",
    "\n",
    "    dfCompetitors_Ml =  dfCompetitors[dfCompetitors['Cantidad'] != 0].reset_index(drop = True)\n",
    "    dfCompetitors_Aux = dfCompetitors[dfCompetitors['Cantidad'] == 0].reset_index(drop = True)\n",
    "\n",
    "    dfCompetitors_Aux = extract_weight(dfCompetitors_Aux)\n",
    "\n",
    "    return pd.concat([dfCompetitors_Ml, dfCompetitors_Aux], ignore_index = True)\n",
    "\n",
    "def compare_rows(dfTo_Compare, intPosition_Fst_Row, intPosition_Sec_Row):\n",
    "    lstColumn_Names = dfTo_Compare.columns.to_list()\n",
    "\n",
    "    dicResult = {}\n",
    "    for strColumn_name in lstColumn_Names:\n",
    "        rowFirst_Value = dfTo_Compare.loc[intPosition_Fst_Row, strColumn_name]\n",
    "        rowSecond_Value = dfTo_Compare.loc[intPosition_Fst_Row, strColumn_name]\n",
    "\n",
    "        if pd.isna(rowFirst_Value) and pd.isna(rowSecond_Value):\n",
    "            dicResult[strColumn_name] = True\n",
    "\n",
    "        else:\n",
    "            dicResult[strColumn_name] = rowFirst_Value == rowSecond_Value\n",
    "\n",
    "    return dicResult\n",
    "\n",
    "def homogonize_column_names(lstColumns):\n",
    "    setColumns_Upper = ['sku', 'upc', 'url sku', 'upc wm']\n",
    "\n",
    "    dictNew_Columns = {}\n",
    "    for strColumn_Name in lstColumns:\n",
    "        strNew_Column = strColumn_Name.lower().replace('_', ' ')\n",
    "\n",
    "        if strNew_Column == 'store id':\n",
    "            dictNew_Columns[strColumn_Name] = 'Store ID'\n",
    "        elif strNew_Column not in setColumns_Upper:\n",
    "            dictNew_Columns[strColumn_Name] = strNew_Column.title()\n",
    "        else:\n",
    "            dictNew_Columns[strColumn_Name] = strNew_Column.upper()\n",
    "\n",
    "    return dictNew_Columns\n",
    "#End File Util Functions\n",
    "\n",
    "#Function get monday date\n",
    "def calculate_update_date():\n",
    "    now = date.today()\n",
    "    monday_date = now - timedelta(days=now.weekday())\n",
    "\n",
    "    return monday_date.isoformat()\n",
    "\n",
    "#Function get counts Date and UPC grouping\n",
    "def getCounts(dfCompetitors):\n",
    "    dfGrouping = dfCompetitors.groupby(by=[\"Date\",\"UPC WM\"]).size().reset_index(name='counts')\n",
    "    dfCompetitors = pd.merge(dfCompetitors, dfGrouping, on=[\"Date\", \"UPC WM\"])\n",
    "    return dfCompetitors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c6c66-2003-4a69-be13-ad5dcd829480",
   "metadata": {},
   "source": [
    "# DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703eb1a-eade-4d95-8fab-c8d4593d1e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "now= datetime.datetime.now()\n",
    "dt_format = '%Y-%m-%d'\n",
    "strToday = now.strftime(dt_format)\n",
    "strToday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e054b1f-ed0f-4fdd-9e0e-5f5d7baa593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(path_base+client_file_name)\n",
    "#RENAME COLUMN TO BE ITEM FOR ITEM DESCRIPTION AND UPC FOR SKU/EAN/UPC/ART ID\n",
    "df_base.rename(columns={ df_base.columns[1]: \"Item\" }, inplace = True)\n",
    "df_base.rename(columns={ df_base.columns[0]: \"UPC\" }, inplace = True)\n",
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81e7b4-48c8-4f47-a835-7e9319deef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparar = consolidate_competitors_df(path_comparar)\n",
    "df_comparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e41bc0-589b-4a3f-85c7-0e4a6d264f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparar['COMP'] =df_comparar['Store ID']+\" \"+ df_comparar['Category']+\" \"+df_comparar['Marca']+\" \"+df_comparar['Item']\n",
    "df_comparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc402b1-46f5-42a6-90c7-519466b8cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparar['Store ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d067bb7-cd03-4dc2-9d82-b1286cc9c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = pd.read_excel(path+filter_file_name)\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f835c0-30f7-4903-bbe2-3ee4415ba121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filter[df_filter['flag'].isin(['x', '{all}'])]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c4b30-0ea2-4a78-8c3e-267eed0025a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa2c489-f48a-45fa-99bf-e457c8d83792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172106d-825d-4b25-916e-69e317a65b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado_final = pd.DataFrame()  # DataFrame final para almacenar todos los resultados\n",
    "\n",
    "# Obtener los diferentes Store ID en df_comparar\n",
    "store_ids = df_comparar['Store ID'].unique()\n",
    "\n",
    "# Función para encontrar las mejores coincidencias\n",
    "def encontrar_coincidencias(item, lista_comparar, top_n=5):\n",
    "    return process.extract(item, lista_comparar, limit=top_n, scorer=fuzz.token_sort_ratio)\n",
    "\n",
    "total_productos = len(df_base)\n",
    "\n",
    "# Iterar sobre cada Store ID\n",
    "for store_id in store_ids:\n",
    "    df_comparar_filtrado = df_comparar[df_comparar['Store ID'] == store_id]\n",
    "    \n",
    "    # Crear un DataFrame temporal para almacenar los resultados de cada Store ID\n",
    "    df_resultado = df_base.copy()\n",
    "    for i in range(5):  # Añadir columnas para hasta 5 sugerencias\n",
    "        df_resultado[f'Tipo de Comparación {i+1}'] = \"\"\n",
    "        df_resultado[f'UPC Sugerido {i+1}'] = \"\"\n",
    "        df_resultado[f'Descripción de producto Sugerido {i+1}'] = \"\"\n",
    "        df_resultado[f'Puntuación {i+1}'] = \"\"\n",
    "        df_resultado[f'URL SKU Sugerido {i+1}'] = \"\"\n",
    "        df_resultado[f'Imagen Sugerida {i+1}'] = \"\"\n",
    "        df_resultado[f'Precio Final Sugerido {i+1}'] = \"\"\n",
    "\n",
    "    # Cruce por UPC y comparación de texto\n",
    "    for index, row in df_base.iterrows():\n",
    "        producto_actual = index + 1\n",
    "        print(f\"------ {producto_actual} out of {total_productos} ---- {producto_actual / total_productos:.1%} ------\")\n",
    "        \n",
    "        upc = row['UPC']\n",
    "        item = row['Item']\n",
    "        if upc in df_comparar_filtrado['UPC'].values:\n",
    "            coincidencia_directa = df_comparar_filtrado[df_comparar_filtrado['UPC'] == upc].iloc[0]\n",
    "            df_resultado.at[index, 'Tipo de Comparación 1'] = \"Idéntico\"\n",
    "            descripcion = df_comparar_filtrado.loc[df_comparar_filtrado['UPC'] == upc, 'Item'].iloc[0]\n",
    "            df_resultado.at[index, 'Descripción de producto Sugerido 1'] = descripcion\n",
    "            df_resultado.at[index, 'UPC Sugerido 1'] = upc\n",
    "            df_resultado.at[index, 'Puntuación 1'] = 100\n",
    "            df_resultado.at[index, 'URL SKU Sugerido 1'] = coincidencia_directa['URL SKU']\n",
    "            df_resultado.at[index, 'Imagen Sugerida 1'] = coincidencia_directa['Image']\n",
    "            df_resultado.at[index, 'Precio Final Sugerido 1'] = coincidencia_directa['Final Price']\n",
    "\n",
    "        else:\n",
    "            coincidencias = encontrar_coincidencias(item, df_comparar_filtrado['Item'].tolist())\n",
    "            for i, (desc, score) in enumerate(coincidencias):\n",
    "                fila_sugerida = df_comparar_filtrado[df_comparar_filtrado['Item'] == desc].iloc[0]\n",
    "                df_resultado.at[index, f'Tipo de Comparación {i+1}'] = \"Sugerido\"\n",
    "                upc_sugerido = df_comparar_filtrado[df_comparar_filtrado['Item'] == desc]['UPC'].iloc[0]\n",
    "                url_sugerido = df_comparar_filtrado[df_comparar_filtrado['Item'] == desc]['URL SKU'].iloc[0]\n",
    "                precio_sugerido = df_comparar_filtrado[df_comparar_filtrado['Item'] == desc]['Final Price'].iloc[0]\n",
    "                df_resultado.at[index, f'UPC Sugerido {i+1}'] = upc_sugerido\n",
    "                df_resultado.at[index, f'Descripción de producto Sugerido {i+1}'] = desc\n",
    "                df_resultado.at[index, f'Puntuación {i+1}'] = score\n",
    "                df_resultado.at[index, f'URL SKU Sugerido {i+1}'] = fila_sugerida['URL SKU']\n",
    "                df_resultado.at[index, f'Imagen Sugerida {i+1}'] = fila_sugerida['Image']\n",
    "                df_resultado.at[index, f'Precio Final Sugerido {i+1}'] = fila_sugerida['Final Price']\n",
    "\n",
    "    # Agregar los resultados del Store ID actual al DataFrame final\n",
    "    df_resultado_final = pd.concat([df_resultado_final, df_resultado], ignore_index=True)\n",
    "\n",
    "df_resultado_final\n",
    "# Al final tendrás todos los resultados en df_resultado_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29831412-882a-46c8-a436-1e0950d113d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_salida = final_file_name\n",
    "df_resultado_final.to_csv(archivo_salida, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c2e5d-9026-4c8d-ae99-db8675abba98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
